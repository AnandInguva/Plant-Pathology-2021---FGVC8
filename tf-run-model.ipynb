{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n# #         print(os.path.join(dirname, filename\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n# !pip install focal-loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T05:43:00.874752Z","iopub.execute_input":"2021-05-31T05:43:00.875425Z","iopub.status.idle":"2021-05-31T05:43:00.879811Z","shell.execute_reply.started":"2021-05-31T05:43:00.875377Z","shell.execute_reply":"2021-05-31T05:43:00.879047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ideas\n1. Perform a binary model for healthy vs not healthy. Then check for the illness if it's not healthy.\n    1. Don't run it on Complex. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport sklearn\n\nimport numpy as np\nimport os\nimport cv2\nimport PIL\nimport sklearn\nimport matplotlib.pyplot\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport time\nimport collections\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# from augmentations import *\n# from helper import *\nimport tensorflow_addons as tfa\nimport albumentations\nfrom albumentations import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Cutout)\nimport csv","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:00.884206Z","iopub.execute_input":"2021-05-31T05:43:00.884534Z","iopub.status.idle":"2021-05-31T05:43:00.897198Z","shell.execute_reply.started":"2021-05-31T05:43:00.884477Z","shell.execute_reply":"2021-05-31T05:43:00.896357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_dir = '../input/resized-plant2021/img_sz_640/'\nimgs_dir = os.path.join(main_dir)\nlabels_path = os.path.join('../input/plant-pathology-2021-fgvc8/', 'train.csv')\n\ndf = pd.read_csv(labels_path)\n\nimage_names = df['image']\nimage_names = [os.path.join(imgs_dir, fname) for fname in image_names]\ndf['image'] = image_names\n\nunique_labels = sorted(df['labels'].unique())\n\n\n# print(\"Total classes : \", num_classes)\nprint(\"Total Samples : \", len(df))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:00.898871Z","iopub.execute_input":"2021-05-31T05:43:00.899694Z","iopub.status.idle":"2021-05-31T05:43:00.973123Z","shell.execute_reply.started":"2021-05-31T05:43:00.899649Z","shell.execute_reply":"2021-05-31T05:43:00.972148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels that will be used for validation\nfinal_labels_for_submission = ['complex', 'frog_eye_leaf_spot', 'frog_eye_leaf_spot complex', 'healthy', 'powdery_mildew', 'powdery_mildew complex', 'rust', 'rust complex', 'rust frog_eye_leaf_spot', 'scab', 'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex',\n                                'complex frog_eye_leaf_spot', 'complex powdery_mildew', 'complex rust', 'frog_eye_leaf_spot rust', 'frog_eye_leaf_spot scab', 'scab complex frog_eye_leaf_spot', 'frog_eye_leaf_spot scab complex', 'frog_eye_leaf_spot complex scab', 'complex frog_eye_leaf_spot scab', 'complex scab frog_eye_leaf_spot']","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:00.976155Z","iopub.execute_input":"2021-05-31T05:43:00.976572Z","iopub.status.idle":"2021-05-31T05:43:00.983251Z","shell.execute_reply.started":"2021-05-31T05:43:00.976531Z","shell.execute_reply":"2021-05-31T05:43:00.981954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_labels\nsingle_labels = []\nfor label in unique_labels:\n    if ' ' not in label:\n        single_labels.append(label)\n\nunique_labels = single_labels.copy()\nnum_classes = len(unique_labels)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:00.985919Z","iopub.execute_input":"2021-05-31T05:43:00.98639Z","iopub.status.idle":"2021-05-31T05:43:00.992873Z","shell.execute_reply.started":"2021-05-31T05:43:00.986349Z","shell.execute_reply":"2021-05-31T05:43:00.991782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading 2020 dataset\npath_2020 = '../input/plant-pathology-2020-fgvc7'\ndf_2020 = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\n\ncolumns = df_2020.columns.tolist()\ncolumns[2] = 'complex'\ncolumns[0] = 'image'\n\ndf_2020.columns = columns\n\nimage_filenames_2020 = df_2020['image'].tolist()\nimage_filenames_2020 = [os.path.join(path_2020, 'images', name) + '.jpg' for name in image_filenames_2020]\n\ndf_2020['image'] = image_filenames_2020\n\nclasses_2020 = ['healthy', 'complex', 'rust', 'scab']\nclasses_to_add = []\nfor lbl in unique_labels:\n    if lbl not in classes_2020:\n        classes_to_add.append(lbl)\n\nclasses_2020 = sorted(classes_2020 + classes_to_add)\n\ndf_2020[classes_to_add[0]] = [0] * len(df_2020)\ndf_2020[classes_to_add[1]] = [0] * len(df_2020)\n\na = df_2020.loc[3, unique_labels].tolist()\nlabels_cat_2020 = []\nfor i in range(len(df_2020)):\n    current_row = df_2020.loc[i, unique_labels].tolist()\n    current_label = []\n    for i, row in enumerate(current_row):\n        if row:\n            current_label.append(unique_labels[i])\n    labels_cat_2020.append(''.join(current_label))    \ndf_2020['underlying_labels'] = labels_cat_2020\ndf_2020['labels'] = df_2020['underlying_labels'].apply(lambda x: x.split())","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:00.994978Z","iopub.execute_input":"2021-05-31T05:43:00.995555Z","iopub.status.idle":"2021-05-31T05:43:02.009038Z","shell.execute_reply.started":"2021-05-31T05:43:00.995515Z","shell.execute_reply":"2021-05-31T05:43:02.007935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.010532Z","iopub.execute_input":"2021-05-31T05:43:02.010942Z","iopub.status.idle":"2021-05-31T05:43:02.028597Z","shell.execute_reply.started":"2021-05-31T05:43:02.010891Z","shell.execute_reply":"2021-05-31T05:43:02.027346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = df['labels'].tolist().copy()\ndf['labels'] = df['labels'].apply(lambda x : x.split(' '))\ndf['underlying_labels'] = class_labels","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.030398Z","iopub.execute_input":"2021-05-31T05:43:02.030814Z","iopub.status.idle":"2021-05-31T05:43:02.052801Z","shell.execute_reply.started":"2021-05-31T05:43:02.030755Z","shell.execute_reply":"2021-05-31T05:43:02.051808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove duplicates","metadata":{}},{"cell_type":"code","source":"import pickle\ndict_file = open(\"../input/plant-pathology-2021-duplicates/duplicates.pickle\",'rb')\nduplicates = pickle.load(dict_file)\nduplicates_to_remove = []\nfor key,val in duplicates.copy().items():\n    if not val:\n        del duplicates[key]\n    else:\n        duplicates_to_remove.extend(val)\nduplicates_to_remove = set(duplicates_to_remove)\n\nduplicates_mask = df['image'].apply(lambda x: x.split('/')[-1] not in duplicates_to_remove)\nprint('Length of DF before removing duplicates : {}'.format(len(df)))\ndf = df[duplicates_mask]\nprint('Length of DF after removing duplicates : {}'.format(len(df)))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.053921Z","iopub.execute_input":"2021-05-31T05:43:02.054189Z","iopub.status.idle":"2021-05-31T05:43:02.162918Z","shell.execute_reply.started":"2021-05-31T05:43:02.054164Z","shell.execute_reply":"2021-05-31T05:43:02.162084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Multi label for each class","metadata":{}},{"cell_type":"code","source":"for i, class_name in enumerate(unique_labels):\n    df[class_name] = df['labels'].apply(lambda x : int(class_name in x))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.165178Z","iopub.execute_input":"2021-05-31T05:43:02.165873Z","iopub.status.idle":"2021-05-31T05:43:02.254218Z","shell.execute_reply.started":"2021-05-31T05:43:02.16583Z","shell.execute_reply":"2021-05-31T05:43:02.253201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model evaluation metrics\n1. Correlation matrix divergence\n2. Adversarial Validations importances\n\n# For ensembling\n1. Boosting using LightGBM\n","metadata":{}},{"cell_type":"markdown","source":"# Hyper parameters\n","metadata":{}},{"cell_type":"code","source":"img_size = 512\nnum_folds = 5\nseed = 42\n\nIMG_SIZE = img_size\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE= 32\ntfdata_buffer_size = 1000\nlearning_rate = 0.001","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.255723Z","iopub.execute_input":"2021-05-31T05:43:02.25615Z","iopub.status.idle":"2021-05-31T05:43:02.264139Z","shell.execute_reply.started":"2021-05-31T05:43:02.256109Z","shell.execute_reply":"2021-05-31T05:43:02.263164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_2020_dataset = True\nif use_2020_dataset:\n    df = pd.concat([df, df_2020], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.26554Z","iopub.execute_input":"2021-05-31T05:43:02.265806Z","iopub.status.idle":"2021-05-31T05:43:02.277703Z","shell.execute_reply.started":"2021-05-31T05:43:02.26578Z","shell.execute_reply":"2021-05-31T05:43:02.276883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['fold'] = 0\n\n# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf = StratifiedShuffleSplit(n_splits=num_folds, random_state=seed, test_size=0.2)\nfor i, (train_index, test_index) in enumerate(mskf.split(df['image'], df['labels'])):\n    df.iloc[test_index, -1] = i\ndf['fold'] = df['fold'].astype('int')\n    \nmask = df['fold'] == 4\ndf['is_valid'] = mask\n\n\ntrain_df = df[df['is_valid'] == False]\nval_df = df[df['is_valid'] == True]\n\nclass_mapping = {}\n\nfor i in range(len(unique_labels)):\n    class_mapping[unique_labels[i]] = i\n\nclasses = list(class_mapping.keys())\n\nlabel_to_cat_label_map = {}\nfor key, value in class_mapping.items():\n    label_to_cat_label_map[value] = key\n\n# train_df['encoded_labels'] = train_df['underlying_labels'].apply(lambda x: class_mapping[x])\n# val_df['encoded_labels'] = val_df['underlying_labels'].apply(lambda x : class_mapping[x])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.279534Z","iopub.execute_input":"2021-05-31T05:43:02.279892Z","iopub.status.idle":"2021-05-31T05:43:02.377359Z","shell.execute_reply.started":"2021-05-31T05:43:02.279855Z","shell.execute_reply":"2021-05-31T05:43:02.376527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_filenames = train_df['image'].tolist()\n# train_filenames = [os.path.join(imgs_dir, fname) for fname in train_filenames]\n# train_labels = tf.keras.utils.to_categorical(train_df['encoded_labels'].tolist())\ntrain_labels = train_df[unique_labels].to_numpy()\nval_filenames = val_df['image'].tolist()\n# val_filenames = [os.path.join(imgs_dir, fname) for fname in val_filenames]\n# val_labels = tf.keras.utils.to_categorical(val_df['encoded_labels'].tolist())\nval_labels = val_df[unique_labels].to_numpy()\n\ntrain_cat_labels = train_df['underlying_labels'].tolist()\nval_cat_labels = val_df['underlying_labels'].tolist()\n\n\ntest_filenames = os.listdir('../input/plant-pathology-2021-fgvc8/test_images/')\ntest_filenames = [os.path.join('../input/plant-pathology-2021-fgvc8/test_images/', name) for name in test_filenames]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.378814Z","iopub.execute_input":"2021-05-31T05:43:02.379176Z","iopub.status.idle":"2021-05-31T05:43:02.388471Z","shell.execute_reply.started":"2021-05-31T05:43:02.379141Z","shell.execute_reply":"2021-05-31T05:43:02.387597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train samples : {}'.format(len(train_filenames)))\nprint('Validation samples : {}'.format(len(val_filenames)))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.39288Z","iopub.execute_input":"2021-05-31T05:43:02.393479Z","iopub.status.idle":"2021-05-31T05:43:02.402282Z","shell.execute_reply.started":"2021-05-31T05:43:02.393439Z","shell.execute_reply":"2021-05-31T05:43:02.401181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def view_image(ds):\n    try:\n        image, cat_label, filename, class_name = next(iter(ds)) # extract 1 batch from the dataset\n    except ValueError as e:\n        image, cat_label = next(iter(ds))\n    image = image.numpy()\n    cat_label = cat_label.numpy()\n\n    fig = plt.figure(figsize=(22, 22))\n    for i in range(8):\n        ax = fig.add_subplot(4, 2, i+1, xticks=[], yticks=[])\n        ax.imshow(image[i])\n        ax.set_title(f\"Label: {cat_label[i]}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.40437Z","iopub.execute_input":"2021-05-31T05:43:02.404763Z","iopub.status.idle":"2021-05-31T05:43:02.412432Z","shell.execute_reply.started":"2021-05-31T05:43:02.404725Z","shell.execute_reply":"2021-05-31T05:43:02.411551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Preprocessing","metadata":{}},{"cell_type":"code","source":"def load_image(img):\n    return img\n\n###############################################################################\ndef init_grabcut_mask(h, w):\n    mask = np.ones((h, w), np.uint8) * cv2.GC_PR_BGD\n    mask[h//4:3*h//4, w//4:3*w//4] = cv2.GC_PR_FGD\n    mask[2*h//5:3*h//5, 2*w//5:3*w//5] = cv2.GC_FGD\n    return mask\n\ndef remove_background(image):\n    h, w = image.shape[:2]\n    mask = init_grabcut_mask(h, w)\n    bgm = np.zeros((1, 65), np.float64)\n    fgm = np.zeros((1, 65), np.float64)\n    cv2.grabCut(image, mask, None, bgm, fgm, 1, cv2.GC_INIT_WITH_MASK)\n    mask_binary = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n    result = cv2.bitwise_and(image, image, mask = mask_binary)\n#     add_contours(result, mask_binary) # optional, adds visualizations\n    return result\n\ndef tf_remove_background(image):\n    image_without_background = tf.numpy_function(remove_background, inp=[image], Tout=[image.dtype])\n    return image_without_background[0]\n\n##################################################################\n\ndef image_resize(image, img_size, inter = cv2.INTER_AREA):\n    dim = None\n    (h, w) = (img_size, img_size)\n    resized = cv2.resize(image, dim, interpolation = inter)\n    return resized\n\ndef remove_local_average_color(img):\n    # print(\"Removing local average color\")\n    scale = 300\n    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # OpenCV processes in BGR\n    output_bgr = cv2.addWeighted(img_bgr, 4, cv2.GaussianBlur(img_bgr, (0, 0), scale / 10), -4, 128)\n    output_rgb = cv2.cvtColor(output_bgr, cv2.COLOR_BGR2RGB)\n    return output_rgb\n\ndef clahe_LAB(img):\n    # print(\"CLAHE LAB\")\n    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # OpenCV processes in BGR\n    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n    lab_planes = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    lab_planes[0] = clahe.apply(lab_planes[0])\n    lab = cv2.merge(lab_planes)\n    output_bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n    output_rgb = cv2.cvtColor(output_bgr, cv2.COLOR_BGR2RGB)\n    return output_rgb\n\ndef clahe_HSV(img):\n    # print(\"CLAHE HSV\")\n    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # OpenCV processes in BGR\n    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n    hsv_planes = cv2.split(hsv)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    hsv_planes[2] = clahe.apply(hsv_planes[2])\n    hsv = cv2.merge(hsv_planes)\n    output_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    output_rgb = cv2.cvtColor(output_bgr, cv2.COLOR_BGR2RGB)\n    return output_rgb\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.413879Z","iopub.execute_input":"2021-05-31T05:43:02.41447Z","iopub.status.idle":"2021-05-31T05:43:02.432191Z","shell.execute_reply.started":"2021-05-31T05:43:02.414435Z","shell.execute_reply":"2021-05-31T05:43:02.431515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create a base train and val dataloader","metadata":{}},{"cell_type":"code","source":"def get_image_dontnormalize(filename, categorical_label, image_size, class_name, preprocess_method=None):\n    # decode_jpeg\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string)  # decodes to uint8 tensor\n#     image_no_background = tf_remove_background(image_decoded)\n    image_resized = tf.cast(tf.image.resize(image_decoded, (image_size, image_size)),\n                            tf.uint8)  # model expects int [0,255]\n\n    return image_resized, categorical_label, filename, class_name\n\ndef create_tf_dataset(image_size,\n                      filenames,\n                      categ_labels,\n                      class_name,\n                      normalize_fn=None,\n                      preprocess_type='none'):\n   \n    image_size_tiled = tf.constant([image_size] * len(filenames))\n    preprocess_type_tiled = tf.constant([preprocess_type] * len(filenames))\n    ds = tf.data.Dataset.from_tensor_slices(\n        (tf.constant(filenames), tf.constant(categ_labels), image_size_tiled,\n         tf.constant(class_name),\n         preprocess_type_tiled)) \\\n        .map(normalize_fn, num_parallel_calls=AUTOTUNE)\n    return ds\n\ndef create_tf_map_dataset(image_size, filenames, categ_labels, class_name, normalize_fn, preprocess_type='none'):\n    '''Uses the given filenames and labels to create tf datasets.'''\n    train_ds = create_tf_dataset(image_size, filenames, categ_labels, class_name, normalize_fn)\n    return train_ds\n\ntrain_ds = create_tf_map_dataset(IMG_SIZE, train_filenames, train_labels, train_cat_labels, normalize_fn=get_image_dontnormalize,)\nval_ds = create_tf_map_dataset(IMG_SIZE, val_filenames, val_labels, val_cat_labels, normalize_fn=get_image_dontnormalize, )\n\n################################################################\ndef create_sampled_dataset(train_ds, unique_labels):\n    df_s = []\n    for value in unique_labels:\n        temp_ds = train_ds.filter(lambda image, categ_label, filename, class_name : class_name == value)\n        df_s.append(temp_ds)\n    return df_s\n    \ndesired_fraction = np.array([1/ len(class_mapping)] * len(class_mapping))\ndfs = create_sampled_dataset(train_ds, unique_labels)\n\nuse_balanced_data = False\nif use_balanced_data:\n    train_data = tf.data.experimental.sample_from_datasets(dfs, desired_fraction)\n    steps_per_epoch = max(1, 2 * len(train_filenames) // BATCH_SIZE)\nelse:\n    steps_per_epoch = max(1, len(train_filenames) // BATCH_SIZE)\n\n################################################################\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.435406Z","iopub.execute_input":"2021-05-31T05:43:02.43565Z","iopub.status.idle":"2021-05-31T05:43:02.50772Z","shell.execute_reply.started":"2021-05-31T05:43:02.435627Z","shell.execute_reply":"2021-05-31T05:43:02.50696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View Class based images","metadata":{}},{"cell_type":"code","source":"# class_names = 'scab frog_eye_leaf_spot complex'\n# temp_df = dfs[class_mapping[class_names]].batch(32)\n# view_image(temp_df)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.509214Z","iopub.execute_input":"2021-05-31T05:43:02.509749Z","iopub.status.idle":"2021-05-31T05:43:02.514197Z","shell.execute_reply.started":"2021-05-31T05:43:02.509711Z","shell.execute_reply":"2021-05-31T05:43:02.513157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nUse mixup on \n\n1. Rust + Complex\n2. scab + frog_eye_leaf_spot\n3. frog_eye_leaf_spot + complex\n4. rust + frog_eye_leaf_spot\n5. powdert_mildew + complex\n6. scab frog_eye_leaf_spot complex\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.516007Z","iopub.execute_input":"2021-05-31T05:43:02.516448Z","iopub.status.idle":"2021-05-31T05:43:02.524942Z","shell.execute_reply.started":"2021-05-31T05:43:02.516408Z","shell.execute_reply":"2021-05-31T05:43:02.524051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batching\n","metadata":{}},{"cell_type":"code","source":"train_data = train_ds.shuffle(buffer_size=tfdata_buffer_size, reshuffle_each_iteration=True,\n                             seed=0)\ntrain_data = train_data.batch(BATCH_SIZE).prefetch(AUTOTUNE)\nval_data = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\ntrain_data = train_data.map(lambda images, categ_labels, filename, class_name: (images, categ_labels))\nval_data_with_filenames = val_data.map(lambda images, categ_labels, filename, class_name: (images, class_name, filename))\nval_data = val_data.map(lambda images, categ_labels, filename, class_name: (images, categ_labels))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.526918Z","iopub.execute_input":"2021-05-31T05:43:02.527497Z","iopub.status.idle":"2021-05-31T05:43:02.553236Z","shell.execute_reply.started":"2021-05-31T05:43:02.52746Z","shell.execute_reply":"2021-05-31T05:43:02.552444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TOTAL_PERCENT_OF_DATA = 100\ndef data_split(images, labels, percent_batch_to_augment):\n    # split the batch with random indices\n    bs = tf.shape(images)[0]\n    indices = tf.range(bs)\n    shuf_indices = indices\n    # shuf_indices = tf.random.shuffle(indices, seed)\n    # shuf_indices = tf.range(bs)\n\n    if percent_batch_to_augment == 0:\n        raise NotImplementedError\n\n    elif percent_batch_to_augment <= 50 or percent_batch_to_augment == 100:\n        unaltered_data = tf.gather(images,\n                                   shuf_indices[:(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment)))])\n        aug_data = tf.gather(images, shuf_indices[(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment))):])\n\n        unaltered_label = tf.gather(labels,\n                                    shuf_indices[:(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment)))])\n        aug_label = tf.gather(labels, shuf_indices[(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment))):])\n\n    elif 50 < percent_batch_to_augment < 100:\n        percent_batch_to_augment = 100 - percent_batch_to_augment\n        aug_data = tf.gather(images, shuf_indices[:(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment)))])\n        unaltered_data = tf.gather(images,\n                                   shuf_indices[(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment))):])\n\n        aug_label = tf.gather(labels, shuf_indices[:(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment)))])\n        unaltered_label = tf.gather(labels,\n                                    shuf_indices[(bs - (bs // (TOTAL_PERCENT_OF_DATA // percent_batch_to_augment))):])\n\n    else:\n        raise NotImplementedError\n\n    return unaltered_data, aug_data, unaltered_label, aug_label\ndef img_flip(image, label, percent_batch_to_augment=100):\n    \"\"\"Flip augmentation\n    Args:\n        percent_batch_to_augment:\n        image: image to flip [bs, img_size, img_size, 3]\n        label: image label (not used)\n\n    Returns:\n        Flipped image, label (shuffled as per augmented image batch)\n    \"\"\"\n    print(\"Using Flip Aug\")\n\n    # split the data into unaltered data and data to be augmented\n    original_data, aug_data, original_label, aug_label = data_split(image, label, percent_batch_to_augment)\n\n    # keep original_data untouched\n    # and flip aug_data\n    flip_half = tf.image.flip_left_right(aug_data)\n    # Concat image and labels\n    images_all = tf.concat([original_data, flip_half], 0)\n    label = tf.concat([original_label, aug_label], 0)\n\n    return images_all, label\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    return image, label   \n\ntrain_data = train_data.map(lambda x, y: img_flip(x, y))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.554795Z","iopub.execute_input":"2021-05-31T05:43:02.555146Z","iopub.status.idle":"2021-05-31T05:43:02.90697Z","shell.execute_reply.started":"2021-05-31T05:43:02.555112Z","shell.execute_reply":"2021-05-31T05:43:02.906161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_preprocess = False\npreprocess_method = clahe_HSV\ndef preprocess_loader(image, name=None):\n    if name == 'None' or name == None:\n        return image\n    if name == 'clahe_HSV':\n        return clahe_HSV(image)\n    \n    return image\ndef tf_preprocess(images, preprocess_method):\n    images = tf.numpy_function(preprocess_loader, inp=[images, preprocess_method], Tout=[images.dtype])\n    return images[0]\n\ndef preprocess_images(images, labels, preprocess_method):\n    preprocessed_imgs = tf_preprocess(images, preprocess_method)\n    return preprocessed_imgs, labels\n\nif use_preprocess:\n    train_data = train_data.map(lambda x, y: preprocess_images(x, y, preprocess_method='clahe_HSV'))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.908425Z","iopub.execute_input":"2021-05-31T05:43:02.908843Z","iopub.status.idle":"2021-05-31T05:43:02.916021Z","shell.execute_reply.started":"2021-05-31T05:43:02.908805Z","shell.execute_reply":"2021-05-31T05:43:02.915124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"momentum = 0.9\n\n\ndef fire(x, squeeze, expand):\n    y = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation='relu', padding='same')(x)\n    y = tf.keras.layers.BatchNormalization(momentum=momentum)(y)\n    y1 = tf.keras.layers.Conv2D(filters=expand // 2, kernel_size=1, activation='relu', padding='same')(y)\n    y1 = tf.keras.layers.BatchNormalization(momentum=momentum)(y1)\n    y3 = tf.keras.layers.Conv2D(filters=expand // 2, kernel_size=3, activation='relu', padding='same')(y)\n    y3 = tf.keras.layers.BatchNormalization(momentum=momentum)(y3)\n    return tf.keras.layers.concatenate([y1, y3])\n\n\ndef fire_module(squeeze, expand):\n    return lambda x: fire(x, squeeze, expand)\n\n\ndef build_model(input_img_shape=None, num_classes=None, unfreeze_layers=False, init_from_rand=False, extend_model=False,\n                perform_regularization=False, regularizer_type='l1', regularization_penalty=0.001,\n                preprocessing_layer=None):\n    x = tf.keras.layers.Input(shape=[None, None, 3])  # input is 512x512 pixels RGB\n    y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation='relu')(x)\n    y = tf.keras.layers.BatchNormalization(momentum=momentum)(y)\n    y = fire_module(24, 48)(y)\n    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n    y = fire_module(48, 96)(y)\n    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n    y = fire_module(64, 128)(y)\n    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n    y = fire_module(48, 96)(y)\n    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n    y = fire_module(24, 48)(y)\n    y = tf.keras.layers.GlobalAveragePooling2D()(y)\n    y = tf.keras.layers.Dense(num_classes, activation='sigmoid')(y)\n    model = tf.keras.Model(x, y)\n    return model\n\ndef base_cnn(dim_input, dim_output, perform_regularization=False, regularizer_type='l1',\n                  regularization_penalty=0.001, preprocessing_layer=None):\n\n    # Convolution Blocks\n    cnn_head = tf.keras.Sequential()\n\n    # Convolutional block 1 (Conv Units - 2)\n    cnn_head.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=dim_input, padding='same', activation='relu'))\n    cnn_head.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n    cnn_head.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    cnn_head.add(tf.keras.layers.BatchNormalization())\n\n\n    # Convolutional block 3 (Conv Units - 3)\n    cnn_head.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n    cnn_head.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n    cnn_head.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n    cnn_head.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    cnn_head.add(tf.keras.layers.BatchNormalization())\n\n    # Fully Connected Layers\n    fc = tf.keras.Sequential()\n    fc.add(tf.keras.layers.AveragePooling2D())\n    fc.add(tf.keras.layers.Flatten())\n    fc.add(tf.keras.layers.Dense(1024, activation='relu'))\n    fc.add(tf.keras.layers.Dense(1024, activation='relu'))\n    fc.add(tf.keras.layers.Dense(512, activation='relu'))\n    fc.add(tf.keras.layers.Dense(dim_output, activation='sigmoid'))\n\n    model = tf.keras.Sequential([\n        cnn_head,\n        fc\n    ])\n\n    # add preprocessing layer\n    if preprocessing_layer is not None:\n        inputs = tf.keras.Input(shape=dim_input, dtype=tf.uint8)\n        x = tf.cast(inputs, tf.float32)\n        x = preprocessing_layer(x)\n        outputs = model(x)\n        model = tf.keras.Model(inputs, outputs)\n\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.918067Z","iopub.execute_input":"2021-05-31T05:43:02.918712Z","iopub.status.idle":"2021-05-31T05:43:02.941657Z","shell.execute_reply.started":"2021-05-31T05:43:02.918677Z","shell.execute_reply":"2021-05-31T05:43:02.940749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations\n","metadata":{}},{"cell_type":"markdown","source":"* ***Create a high level order function for the augmentations to be in the model itself such that it would use GPU acceleration***\n1. Check why Zoom, sharpen, rotate are not working.\n2. Implement cutout, mixup","metadata":{}},{"cell_type":"code","source":"from albumentations import VerticalFlip, Flip, MotionBlur, MedianBlur, GlassBlur, GaussNoise, RandomBrightnessContrast, RandomScale, GaussianBlur, RandomBrightness, RandomContrast, ShiftScaleRotate, Compose\n\n# def strong_aug(p=1):\n    \n#     augs = Compose([Flip(p=p), GaussianBlur(p=p), RandomBrightness(p=p), RandomContrast(p=p), ShiftScaleRotate(p=p)])\n#     return augs\n\n# def strong_aug(p=0.5):\n#     return Compose([\n#         RandomRotate90(),\n#         Flip(),\n#         Transpose(),\n#         OneOf([\n#             IAAAdditiveGaussianNoise(),\n#             GaussNoise(),\n#         ], p=0.2),\n#         OneOf([\n#             MotionBlur(p=0.2),\n#             MedianBlur(blur_limit=3, p=0.1),\n#             Blur(blur_limit=3, p=0.1),\n#         ], p=0.2),\n#         ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n#         OneOf([\n#             OpticalDistortion(p=0.3),\n#             GridDistortion(p=0.1),\n#             IAAPiecewiseAffine(p=0.3),\n#         ], p=0.2),\n#         OneOf([\n# #             CLAHE(clip_limit=2),\n#             IAASharpen(),\n#             IAAEmboss(),\n#             RandomBrightnessContrast(),\n#         ], p=0.3),\n#         HueSaturationValue(p=0.3),\n#     ], p=p)\n# transforms = strong_aug(p=0.7)\n\ndef augmentations(p=0.5):\n    \n    transforms = Compose([RandomBrightness(p=p), RandomContrast(p=p), Flip(p=p)])\n    return transforms\n\ntransforms = augmentations(p=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.943445Z","iopub.execute_input":"2021-05-31T05:43:02.943836Z","iopub.status.idle":"2021-05-31T05:43:02.953564Z","shell.execute_reply.started":"2021-05-31T05:43:02.943799Z","shell.execute_reply":"2021-05-31T05:43:02.952518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img = plt.imread(train_filenames[0])\n# img_t = augment_image(img)\n# # print(img_t.shape)\n# print(np.max(img), np.max(img_t))\n# plt.imshow(img_t)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.956263Z","iopub.execute_input":"2021-05-31T05:43:02.956649Z","iopub.status.idle":"2021-05-31T05:43:02.963716Z","shell.execute_reply.started":"2021-05-31T05:43:02.956616Z","shell.execute_reply":"2021-05-31T05:43:02.962995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_image(image):\n    data = {'image' : image}\n    data_transform = transforms(**data)\n    img_transformed = data_transform['image']\n    return img_transformed\n\ndef tf_augment_image(images):\n    images = tf.numpy_function(augment_image, inp=[images], Tout=[images.dtype])\n    return images[0]\n\ndef augment_batches(images, labels):\n    # tf.map_fn : takes batches of images, unroll the batches\n    # perfom op on every image in batch and rolls back to batch\n    aug_images = tf.map_fn(tf_augment_image, images)\n    aug_images = tf.reshape(aug_images, shape=tf.shape(images))\n    return aug_images, labels\n\ndef augment_in_model(images):\n    aug_images = tf.map_fn(tf_augment_image, images)\n    aug_images = tf.reshape(aug_images, shape=tf.shape(images))\n    return aug_images\n\nclass AugmentationLayer(tf.keras.layers.Layer):\n    \n    def __init__(self, augmentation_function, name=None, **kwargs):\n        super(AugmentationLayer, self).__init__(name=name)\n        self.augmentation_function = augmentation_function\n        super(AugmentationLayer, self).__init__(**kwargs)\n\n    def call(self, images, training=False):\n        if not training:\n            return images\n        augmented_images = self.augmentation_function(images)\n        return augmented_images\n    \n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'augmentation_function': self.augmentation_function \n        })\n        return config\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.966807Z","iopub.execute_input":"2021-05-31T05:43:02.967083Z","iopub.status.idle":"2021-05-31T05:43:02.983014Z","shell.execute_reply.started":"2021-05-31T05:43:02.967059Z","shell.execute_reply":"2021-05-31T05:43:02.981162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize augmented images","metadata":{}},{"cell_type":"markdown","source":"# Callbacks","metadata":{}},{"cell_type":"code","source":"def saveModelOnMetric(save_dir, metric='val_loss', mode='min', save_freq='epoch', save_best_only=True,\n                      save_weights_only=True):\n    checkpoint_path = os.path.join(save_dir, 'model_weights/best_model_on_{}_weights.h5'.format(metric))\n    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                             monitor=metric,\n                                                             save_freq='epoch',\n                                                             save_best_only=save_best_only,\n                                                             save_weights_only=save_weights_only,\n                                                             mode=mode)\n    return checkpoint_callback\n\n# learning_rate = tf.keras.experimental.CosineDecay(initial_learning_rate=learning_rate,\n#                                                decay_steps=1000)\n\nsave_dir = '.'\nsave_best_model_cbk_on_val_loss = saveModelOnMetric(save_dir,\n                                                    metric='val_loss',\n                                                    mode='min',\n                                                    save_weights_only=False)\nsave_best_model_cbk_on_val_f1 = saveModelOnMetric(save_dir,\n                                                   metric='val_F1',\n                                                   mode='max',\n                                                 save_weights_only=False)\ncsv_logger = tf.keras.callbacks.CSVLogger(os.path.join(save_dir, 'metrics.csv'), append=True)\n\n######################################################\n# write a callback for validation predictions\n######################################################\ndef cosineLearningRateCallback(initial_learning_rate, decay_steps=100000, alpha=0.0, name=None):\n    lr_schedule = tf.keras.experimental.CosineDecay(initial_learning_rate=initial_learning_rate,\n                                                    decay_steps=decay_steps,\n                                                    alpha=alpha,\n                                                    name=name)\n    return lr_schedule\n\nclass metricStatistics(tf.keras.callbacks.Callback):\n\n    def __init__(self, val_data, save_dir, classes, save_freq=10):\n        super(metricStatistics, self).__init__()\n        self.val_data = val_data\n        self.save_dir = save_dir\n        self.save_freq = save_freq\n        self.classes = classes\n        # metrics\n        self.f1, self.val_f1 = [], []\n        self.loss, self.val_loss = [], []\n\n    # Function for calculating model.predict() on a tf Dataset\n    def predict_on_data(self, data, name='train'):\n        filenames = []\n        if name == 'validation':\n            filenames = np.array(list(data.flat_map(\n                lambda image, label, filename: tf.data.Dataset.from_tensor_slices(filename)).as_numpy_iterator()))\n            data = data.map(lambda image, label, filename: (image, label))\n        true_labels = np.array(\n            list(data.flat_map(lambda image, label: tf.data.Dataset.from_tensor_slices(label)).as_numpy_iterator()))\n        predicted_values = self.model.predict(data)\n#         predicted_values = np.reshape(predicted_values, -1)\n        predicted_values = self.convert_categorical_to_label(predicted_values)\n        if name == 'validation':\n            return true_labels, predicted_values, filenames\n    \n\n    def save_validation_predictions(self, epoch, labels, values, filenames, name=None):\n        if name is None:\n            csv_filename = os.path.join(self.save_dir, 'val_predictions_at_epoch_{}.csv'.format(epoch))\n        else:\n            csv_filename = os.path.join(self.save_dir, name)\n\n        with open(csv_filename, 'a') as fp:\n            wr = csv.writer(fp, dialect='excel')\n            wr.writerow(['Image name', 'Model Prediction', 'True Label'])\n            for i in range(len(labels)):\n                try:\n                    name = filenames[i].decode('utf-8').split('/')[-1]\n                except AttributeError as e:\n                    name = filenames[i].split('/')[-1]\n                try:\n                    wr.writerow([name, round(values[i], 4), labels[i]])\n                except:\n                    wr.writerow([name, values[i], labels[i]])                    \n            fp.close()\n    \n    \n    def unroll_dataloader(self, epoch, logs):\n        val_labels, val_values, val_filenames = self.predict_on_data(self.val_data, 'validation')\n        return val_labels, val_values, val_filenames\n    \n    def convert_categorical_to_label(self, predictions):\n        labels = []\n        predictions[predictions < 0.5] = 0\n        predictions[predictions >= 0.5] = 1\n        for i in predictions:\n            arr = np.nonzero(i)\n            lbl = []\n            if len(arr[0]) >= 1:\n                for j in arr[0]:\n                    lbl.append(label_to_cat_label_map[j])\n                final_cat_label = ' '.join(lbl)\n                labels.append(final_cat_label)\n            else:\n                labels.append('None')\n        return labels\n\n        \n    def on_epoch_end(self, epoch, logs=None):\n        self.loss.append(logs['loss'])\n        self.val_loss.append(logs['val_loss'])\n        self.f1.append(logs['F1'])\n        self.val_f1.append(logs['val_F1'])\n\n        if epoch != 0 and epoch % self.save_freq == 0:\n            val_labels, val_values, val_filenames = self.unroll_dataloader(epoch, logs)\n            self.save_validation_predictions(epoch, val_labels, val_values, val_filenames)\n            \n\nsave_validation_prediction = metricStatistics(save_dir=save_dir, classes=num_classes, save_freq=1, val_data=val_data_with_filenames)\n\nuse_learning_rate_decay = True\nif use_learning_rate_decay:\n    learning_rate = cosineLearningRateCallback(initial_learning_rate=learning_rate)\n    \ncallbacks = [save_best_model_cbk_on_val_f1, \n             save_best_model_cbk_on_val_loss, csv_logger, save_validation_prediction]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:02.987236Z","iopub.execute_input":"2021-05-31T05:43:02.993287Z","iopub.status.idle":"2021-05-31T05:43:03.035561Z","shell.execute_reply.started":"2021-05-31T05:43:02.993237Z","shell.execute_reply":"2021-05-31T05:43:03.033987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.MobileNet(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model.trainable = False\n# base_model.summary()\nnum_classes = len(unique_labels)\npreprocessor = tf.keras.applications.mobilenet.preprocess_input\n#add classification head\nimage_batch, label_batch = next(iter(train_data))\nfeature_batch = base_model(image_batch)\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprediction_layer = tf.keras.layers.Dense(num_classes, activation='sigmoid')\n\ndata_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])\ninputs = tf.keras.Input(shape=(None, None, 3))\n# x = data_augmentation(inputs)\n# x = AugmentationLayer(augment_in_model)(inputs)\nx = preprocessor(inputs)\nx = base_model(x)\nx = global_average_layer(x)\n# x = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)\nmodel.summary()\n\n# model = base_cnn((512, 512, 3), num_classes)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:03.041968Z","iopub.execute_input":"2021-05-31T05:43:03.044454Z","iopub.status.idle":"2021-05-31T05:43:07.788674Z","shell.execute_reply.started":"2021-05-31T05:43:03.044406Z","shell.execute_reply":"2021-05-31T05:43:07.787231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n# loss_fn =  loss=tf.keras.losses.CosineSimilarity(axis=1)\n# import focal_loss\n# from focal_loss import SparseCategoricalFocalLoss\n# loss_fn = SparseCategoricalFocalLoss(gamma=2, from_logits=True)\nmetrics = ['accuracy', tfa.metrics.F1Score(num_classes=len(unique_labels),\n                                           average='macro',\n                                          name='F1')]\n# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n# model.compile(optimizer=optimizer, loss=loss_fn,metrics=metrics)\nif not os.path.exists('model_weights'):\n    os.makedirs('model_weights')\n    os.makedirs('metrics')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:07.790032Z","iopub.execute_input":"2021-05-31T05:43:07.790377Z","iopub.status.idle":"2021-05-31T05:43:07.804909Z","shell.execute_reply.started":"2021-05-31T05:43:07.790341Z","shell.execute_reply":"2021-05-31T05:43:07.803988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.trainable = True\noptimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss=loss_fn,metrics=metrics)\ntotal_epochs = 20\n# total_epochs = initial_epochs + finetue_epochs\n\nhistory_fine = model.fit(train_data.repeat(), \n                         epochs=total_epochs,\n                         steps_per_epoch=steps_per_epoch,\n#                         initial_epoch=history.epoch[-1],\n                         initial_epoch=0,\n                        validation_data=val_data,\n                         callbacks=callbacks,)\n#                        class_weight=class_weights,)\n#                         batch_size=8)\n\n'''\n1. No AUG400s\n2. with AUG 478 seconds\n3. With data split - 420\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:43:07.80629Z","iopub.execute_input":"2021-05-31T05:43:07.806807Z","iopub.status.idle":"2021-05-31T05:50:25.53106Z","shell.execute_reply.started":"2021-05-31T05:43:07.806638Z","shell.execute_reply":"2021-05-31T05:50:25.527875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_weights/final_model.h5')\nacc = history_fine.history['accuracy']\nval_acc = history_fine.history['val_accuracy']\nloss = history_fine.history['loss']\nval_loss = history_fine.history['val_loss']\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\n# plt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\n# plt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:50:25.531947Z","iopub.status.idle":"2021-05-31T05:50:25.532363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path= ('../input/plant-pathology-2021-fgvc8/test_images/')\ntest_filenames = os.listdir(test_path)\ntest_abs_filenames = [os.path.join(test_path, name) for name in test_filenames]\nimage_size = img_size\ndef test_get_image_dontnormalize(filename, image_size=256, preprocess_method=None):\n    # decode_jpeg\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string)  # decodes to uint8 tensor\n\n#     preprocessed = tf_preprocess(image_decoded, preprocess_method)\n#     preprocessed = tf.reshape(preprocessed, tf.shape(image_decoded))\n\n    # resize image\n    image_resized = tf.cast(tf.image.resize(image_decoded, (image_size, image_size)),\n                            tf.uint8)  # model expects int [0,255]\n\n    return image_resized\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nimg_size_tiled = tf.constant([image_size] * len(test_filenames))\ntest_ds = tf.data.Dataset.from_tensor_slices((tf.constant(test_abs_filenames), img_size_tiled)).map(test_get_image_dontnormalize, num_parallel_calls=AUTOTUNE)\ntest_data = test_ds.batch(64)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:50:25.533487Z","iopub.status.idle":"2021-05-31T05:50:25.53412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T05:50:25.535242Z","iopub.status.idle":"2021-05-31T05:50:25.536129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}